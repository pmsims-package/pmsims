---
title: Testing tuning parameters
date: 2023-06-30
author: Ewan Carr
editor_options: 
  chunk_output_type: console
---

# Testing `tune_generate_data`

```{r}
library(pmsims)
library(tidyverse)
library(evaluate)
library(furrr)
plan(multisession, workers = 20)

run_tune <- function(signal_parameters,
                     min_sample_size,
                     max_sample_size,
                     large_sample_performance) {
  print(c(
    signal_parameters,
    min_sample_size,
    max_sample_size,
    large_sample_performance
  ))
  noise_parameters = 0
  baseline_prob = 0.2
  metric = "auc"
  predictor_type = "continuous"
  predictor_prop = NULL
  n_reps = 10
  minimum_threshold = 0.1
  metric = "auc"
  tune_args = NULL
  verbose = TRUE
  set.seed(42)
  
  inputs <- pmsims::parse_inputs(data_spec = list(
    type = "binary",
    args = list(
      signal_parameters = signal_parameters,
      noise_parameters = noise_parameters,
      predictor_type = predictor_type,
      predictor_prop = predictor_prop,
      baseline_prob = baseline_prob
    )
  ),
  metric)
  
  if (is.null(tune_args$min_tune_arg))
    tune_args$min_tune_arg <- 0
  if (is.null(tune_args$max_tune_arg))
    tune_args$max_tune_arg <- 1
  if (is.null(tune_args$large_n))
    tune_args$large_n <- max_sample_size
  if (is.null(tune_args$tolerance))
    tune_args$tolerance <- large_sample_performance / 100
  if (is.null(tune_args$max_interval_expansion))
    tune_args$max_interval_expansion <- 20
  default <- list(
    data_function = inputs$data_function,
    model_function = inputs$model_function,
    metric_function = inputs$metric_function,
    target_large_sample_performance = large_sample_performance,
    verbose = verbose
  )
  tune_args <- c(tune_args, default)
  
  tune_param <- do.call(tune_generate_data, tune_args)
  return(tune_param)
}

```

```{r}
opts <- expand_grid(
  signal_parameters = c(10, 30, 100, 200),
  min_sample_size = 100,
  max_sample_size = c(100, 200, 1000, 5000),
  large_sample_performance = seq(0.6, 0.9, 0.1)
)

eval_wrapper <- function(signal_parameters,
                         min_sample_size,
                         max_sample_size,
                         large_sample_performance) {
  evaluate(
    str_glue(
      "run_tune({signal_parameters}, {min_sample_size}, {max_sample_size}, {large_sample_performance})"
    ),
    debug = TRUE
  )
}

opts$result <- future_pmap(opts,
                           eval_wrapper,
                           .options = furrr_options(globals = c("str_glue",
                                                                "evaluate",
                                                                "run_tune",
                                                                "tune_generate_data",
                                                                "optimise_me"),
                                                    seed = 42))

```

```{r}
grepl("simpleWarning", opts$result[[1]])
grepl("simpleError", opts$result[[1]])

get_message <- function(r) {
  x <- unique(map_chr(r, \(r) class(r)[2]))
  if ("error" %in% x) return("error")
  if ("warning" %in% x) return("warning")
  return("ok")
}

opts$status <- map_chr(opts$result, get_message)
opts$status <- factor(opts$status, levels = c("error", "warning", "ok"))
```

```{r}
reorder_factor <- function(f, prefix) { reorder(paste(prefix, f), f) }

opts |>
  ggplot() +
  aes(x = factor(min_sample_size),
      y = factor(large_sample_performance),
      color = status) +
  geom_point(size = 5) +
  facet_grid(rows = vars(reorder_factor(max_sample_size, "Max sample:")),
             cols = vars(reorder_factor(signal_parameters, "Signal parameters:"))) +
  labs(y = "Large sample performance",
       color = "Result") +
  scale_color_manual(values = c("darkred", "orange", "darkgreen")) +
  theme_minimal()
```

```{r}
opts$result[[1]]
```